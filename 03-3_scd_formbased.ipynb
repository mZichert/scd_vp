{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c225e85-e346-4443-aedb-7de45ba820f7",
   "metadata": {},
   "source": [
    "## **SCD - Form based**\n",
    "\n",
    "- AID and PRT\n",
    "- https://github.com/glnmario/cwr4lsc/blob/master/change_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaee8d1-43e0-4228-941e-ad17de5604e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import panel as pn\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "\n",
    "journals = [\"pr\", \"pra\", \"prb\", \"prc\", \"prd\", \"pre\", \"prl\", \"rmp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a0a7c-733f-46fd-8228-6006b94e67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word = \"virtual\"\n",
    "    \n",
    "if target_word == \"virtual\":\n",
    "    df = pd.read_pickle(\"../../data/embeddings/virtual_fulltexts_virtual_token_embeddings.pkl\")\n",
    "    df = df.loc[df.token == \"virtual\"].copy()\n",
    "    df[\"joint_sents\"] = df.sentence.apply(lambda x: \"_\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11cd7d-1877-479d-bc35-2a5bb1ef3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize year slices\n",
    "def categorize_year(year, min_year, slice_width):\n",
    "    base_year = min_year + slice_width * ((year - min_year) // slice_width)\n",
    "    return f\"{base_year}-{base_year+slice_width-1}\"\n",
    "\n",
    "print(f\"Anzahl {target_word} embeddings:\", len(df))\n",
    "if target_word == \"virtual\":\n",
    "    print(f\"Anzahl Satzembeddings für Sätze mit {target_word}:\", len(df.drop_duplicates(\"joint_sents\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12724e5-efc1-4c97-b03f-3e96fcaa0356",
   "metadata": {},
   "source": [
    "### **Average Inner Distance**\n",
    "\n",
    "for polysemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc9df4-04b0-47af-aa98-399fef69502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_word == \"virtual\":\n",
    "    embedding_types = [\"token_emb\"]\n",
    "time_slices = [1, 3, 5]\n",
    "metric = \"euclidean\"\n",
    "\n",
    "for emb_type in tqdm(embedding_types):\n",
    "    \n",
    "    for slice_width in tqdm(time_slices):\n",
    "\n",
    "        for journal in [\"all\"] + journals:\n",
    "            \n",
    "            result_dict = {}\n",
    "\n",
    "            if journal == \"all\":\n",
    "                journal_df = df.copy()\n",
    "            else:\n",
    "                journal_df = df.loc[df.journal == journal].copy()\n",
    "            min_year = journal_df.year.min()\n",
    "\n",
    "            # Create year slices:\n",
    "            journal_df['year_slice'] = journal_df['year'].apply(lambda x: categorize_year(x, min_year, slice_width))\n",
    "\n",
    "            for sli, years_slice_df in journal_df.groupby(\"year_slice\"):\n",
    "\n",
    "                aid = np.mean(pdist(years_slice_df[emb_type].to_list(), metric=metric))\n",
    "                result_dict[sli] = aid\n",
    "                \n",
    "            result_df = pd.DataFrame.from_dict(result_dict, orient=\"index\", columns = [f\"{emb_type}_{journal}_{slice_width}\"])\n",
    "            result_df.to_pickle(f\"../../data/scd/fb/aid_{target_word}/{target_word}_aid_{emb_type}_{journal}_{slice_width}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356efebd-16e9-4d36-bf13-b31c04323f58",
   "metadata": {},
   "source": [
    "### **Inverted Cosine Similarity over Word Prototypes (PRT)**\n",
    "\n",
    "- a lá kutuzov et al 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acf6fb-f638-40a4-8e72-f492bb272006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_word == \"virtual\":\n",
    "    embedding_types = [\"token_emb\"]\n",
    "time_slices = [1, 3, 5]\n",
    "inverted = True\n",
    "\n",
    "for emb_type in tqdm(embedding_types):\n",
    "    \n",
    "    for slice_width in tqdm(time_slices):\n",
    "\n",
    "        for journal in [\"all\"] + journals:\n",
    "            \n",
    "            result_dict = {}\n",
    "\n",
    "            if journal == \"all\":\n",
    "                journal_df = df.copy()\n",
    "            else:\n",
    "                journal_df = df.loc[df.journal == journal].copy()\n",
    "            min_year = journal_df.year.min()\n",
    "\n",
    "            if emb_type == \"sentence_emb\":\n",
    "                journal_df = journal_df.drop_duplicates(\"joint_sents\")\n",
    "\n",
    "            # Create year slices:\n",
    "            journal_df['year_slice'] = journal_df['year'].apply(lambda x: categorize_year(x, min_year, slice_width))\n",
    "\n",
    "            start = True\n",
    "\n",
    "            for sli, years_slice_df in journal_df.groupby(\"year_slice\"):\n",
    "\n",
    "                if start:\n",
    "                    # Make Type Embeddings for Time Slice\n",
    "                    last_type_embedding = years_slice_df[emb_type].to_list()\n",
    "                    last_type_embedding = np.mean(last_type_embedding, axis=0)\n",
    "                    start = False\n",
    "                    continue\n",
    "\n",
    "                # Make Type Embeddings for Time Slice\n",
    "                current_type_embedding = years_slice_df[emb_type].to_list()\n",
    "                current_type_embedding = np.mean(current_type_embedding, axis=0)\n",
    "                \n",
    "                if inverted:\n",
    "                    cosine_sim = 1 / (1 - cosine(last_type_embedding, current_type_embedding))\n",
    "                else:\n",
    "                    cosine_sim = 1 - cosine(last_type_embedding, current_type_embedding)\n",
    "                    \n",
    "                result_dict[sli] = cosine_sim\n",
    "\n",
    "                last_type_embedding = current_type_embedding\n",
    "\n",
    "            result_df = pd.DataFrame.from_dict(result_dict, orient=\"index\", columns = [f\"{emb_type}_{journal}_{slice_width}\"])\n",
    "            result_df.to_pickle(f\"../../data/scd/fb/prt_{target_word}/{target_word}_prt_fb_{emb_type}_{journal}_{slice_width}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma-venv",
   "language": "python",
   "name": "ma-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
